2024-02-20 20:34:26.963 | INFO     | tabularbench.core.run_experiment:run_experiment:22 - Start experiment on albert (id=45035) with Foundation doing classification
2024-02-20 20:34:26.964 | INFO     | tabularbench.core.run_experiment:run_experiment:25 - Set seed to 0
2024-02-20 20:34:26.965 | INFO     | tabularbench.core.run_experiment:run_experiment:27 - We are using the following hyperparameters:
2024-02-20 20:34:26.965 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_features: 100
2024-02-20 20:34:26.965 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_classes: 10
2024-02-20 20:34:26.966 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     dim: 512
2024-02-20 20:34:26.966 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_layers: 12
2024-02-20 20:34:26.966 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_heads: 4
2024-02-20 20:34:26.966 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     attn_dropout: 0.0
2024-02-20 20:34:26.966 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     y_as_float_embedding: True
2024-02-20 20:34:26.967 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     linear_attention: True
2024-02-20 20:34:26.967 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     max_samples_support: 10000
2024-02-20 20:34:26.967 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     max_samples_query: 10000
2024-02-20 20:34:26.967 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     max_epochs: 300
2024-02-20 20:34:26.967 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     optimizer: adamw
2024-02-20 20:34:26.967 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     lr: 1e-05
2024-02-20 20:34:26.968 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     weight_decay: 0
2024-02-20 20:34:26.968 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     lr_scheduler: False
2024-02-20 20:34:26.968 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     lr_scheduler_patience: 30
2024-02-20 20:34:26.968 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     early_stopping_patience: 40
2024-02-20 20:34:26.968 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     use_pretrained_weights: True
2024-02-20 20:34:26.968 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     path_to_weights: outputs/2024-02-19/12-38-03/weights/model_step_220000.pt
2024-02-20 20:34:26.969 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_ensembles: 1
2024-02-20 20:34:26.969 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     use_quantile_transformer: True
2024-02-20 20:34:26.969 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     use_feature_count_scaling: True
2024-02-20 20:34:26.969 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     name: Foundation
2024-02-20 20:34:27.498 | INFO     | tabularbench.core.run_experiment:run_experiment_:61 - Start split 1/1 of albert (id=45035) with FOUNDATION doing CLASSIFICATION
2024-02-20 20:34:31.050 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 000 | Train loss: 0.6484 | Train score: 0.6187 | Val loss: 0.6244 | Val score: 0.6540
2024-02-20 20:34:32.419 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 001 | Train loss: 0.6210 | Train score: 0.6625 | Val loss: 0.6228 | Val score: 0.6525
2024-02-20 20:34:33.856 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 002 | Train loss: 0.6260 | Train score: 0.6519 | Val loss: 0.6217 | Val score: 0.6565
2024-02-20 20:34:35.216 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 003 | Train loss: 0.6209 | Train score: 0.6569 | Val loss: 0.6209 | Val score: 0.6545
2024-02-20 20:34:36.570 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 004 | Train loss: 0.6173 | Train score: 0.6581 | Val loss: 0.6204 | Val score: 0.6560
2024-02-20 20:34:38.190 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 005 | Train loss: 0.6251 | Train score: 0.6662 | Val loss: 0.6205 | Val score: 0.6540
2024-02-20 20:34:39.047 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 006 | Train loss: 0.6322 | Train score: 0.6350 | Val loss: 0.6203 | Val score: 0.6510
2024-02-20 20:34:40.521 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 007 | Train loss: 0.6205 | Train score: 0.6538 | Val loss: 0.6200 | Val score: 0.6530
2024-02-20 20:34:42.265 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 008 | Train loss: 0.6259 | Train score: 0.6550 | Val loss: 0.6197 | Val score: 0.6510
2024-02-20 20:34:43.665 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 009 | Train loss: 0.6248 | Train score: 0.6525 | Val loss: 0.6196 | Val score: 0.6510
2024-02-20 20:34:45.052 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 010 | Train loss: 0.6143 | Train score: 0.6650 | Val loss: 0.6197 | Val score: 0.6515
2024-02-20 20:34:45.904 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 011 | Train loss: 0.6240 | Train score: 0.6362 | Val loss: 0.6198 | Val score: 0.6515
2024-02-20 20:34:46.759 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 012 | Train loss: 0.6218 | Train score: 0.6494 | Val loss: 0.6199 | Val score: 0.6510
2024-02-20 20:34:47.614 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 013 | Train loss: 0.6342 | Train score: 0.6450 | Val loss: 0.6200 | Val score: 0.6485
2024-02-20 20:34:48.469 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 014 | Train loss: 0.6109 | Train score: 0.6625 | Val loss: 0.6199 | Val score: 0.6485
2024-02-20 20:34:49.333 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 015 | Train loss: 0.6332 | Train score: 0.6481 | Val loss: 0.6200 | Val score: 0.6505
2024-02-20 20:34:50.197 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 016 | Train loss: 0.6285 | Train score: 0.6475 | Val loss: 0.6200 | Val score: 0.6520
2024-02-20 20:34:51.053 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 017 | Train loss: 0.6227 | Train score: 0.6406 | Val loss: 0.6199 | Val score: 0.6535
2024-02-20 20:34:51.909 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 018 | Train loss: 0.6248 | Train score: 0.6575 | Val loss: 0.6200 | Val score: 0.6515
2024-02-20 20:34:52.765 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 019 | Train loss: 0.6371 | Train score: 0.6337 | Val loss: 0.6201 | Val score: 0.6530
2024-02-20 20:34:53.623 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 020 | Train loss: 0.6199 | Train score: 0.6513 | Val loss: 0.6203 | Val score: 0.6525
2024-02-20 20:34:54.485 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 021 | Train loss: 0.6255 | Train score: 0.6444 | Val loss: 0.6205 | Val score: 0.6520
2024-02-20 20:34:55.342 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 022 | Train loss: 0.6221 | Train score: 0.6600 | Val loss: 0.6205 | Val score: 0.6505
2024-02-20 20:34:56.202 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 023 | Train loss: 0.6234 | Train score: 0.6600 | Val loss: 0.6205 | Val score: 0.6480
2024-02-20 20:34:57.059 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 024 | Train loss: 0.6126 | Train score: 0.6569 | Val loss: 0.6206 | Val score: 0.6475
2024-02-20 20:34:57.917 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 025 | Train loss: 0.6197 | Train score: 0.6550 | Val loss: 0.6211 | Val score: 0.6500
2024-02-20 20:34:58.778 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 026 | Train loss: 0.6258 | Train score: 0.6619 | Val loss: 0.6220 | Val score: 0.6465
2024-02-20 20:34:59.638 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 027 | Train loss: 0.6163 | Train score: 0.6550 | Val loss: 0.6225 | Val score: 0.6475
2024-02-20 20:35:00.497 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 028 | Train loss: 0.6283 | Train score: 0.6600 | Val loss: 0.6221 | Val score: 0.6480
2024-02-20 20:35:01.354 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 029 | Train loss: 0.6155 | Train score: 0.6531 | Val loss: 0.6221 | Val score: 0.6520
2024-02-20 20:35:02.216 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 030 | Train loss: 0.6163 | Train score: 0.6425 | Val loss: 0.6219 | Val score: 0.6525
2024-02-20 20:35:03.073 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 031 | Train loss: 0.6255 | Train score: 0.6425 | Val loss: 0.6216 | Val score: 0.6515
2024-02-20 20:35:03.930 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 032 | Train loss: 0.6306 | Train score: 0.6419 | Val loss: 0.6214 | Val score: 0.6505
2024-02-20 20:35:04.803 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 033 | Train loss: 0.6061 | Train score: 0.6737 | Val loss: 0.6213 | Val score: 0.6500
2024-02-20 20:35:05.711 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 034 | Train loss: 0.6228 | Train score: 0.6581 | Val loss: 0.6216 | Val score: 0.6475
2024-02-20 20:35:06.583 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 035 | Train loss: 0.6120 | Train score: 0.6700 | Val loss: 0.6216 | Val score: 0.6475
2024-02-20 20:35:07.445 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 036 | Train loss: 0.6059 | Train score: 0.6725 | Val loss: 0.6218 | Val score: 0.6490
2024-02-20 20:35:08.312 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 037 | Train loss: 0.6118 | Train score: 0.6662 | Val loss: 0.6225 | Val score: 0.6465
2024-02-20 20:35:09.168 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 038 | Train loss: 0.6034 | Train score: 0.6812 | Val loss: 0.6243 | Val score: 0.6475
2024-02-20 20:35:10.026 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 039 | Train loss: 0.6365 | Train score: 0.6444 | Val loss: 0.6261 | Val score: 0.6500
2024-02-20 20:35:10.885 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 040 | Train loss: 0.6112 | Train score: 0.6587 | Val loss: 0.6274 | Val score: 0.6500
2024-02-20 20:35:11.745 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 041 | Train loss: 0.6099 | Train score: 0.6637 | Val loss: 0.6274 | Val score: 0.6525
2024-02-20 20:35:12.603 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 042 | Train loss: 0.6094 | Train score: 0.6612 | Val loss: 0.6267 | Val score: 0.6475
2024-02-20 20:35:13.462 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 043 | Train loss: 0.6272 | Train score: 0.6544 | Val loss: 0.6255 | Val score: 0.6495
2024-02-20 20:35:14.322 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 044 | Train loss: 0.6052 | Train score: 0.6750 | Val loss: 0.6248 | Val score: 0.6510
2024-02-20 20:35:15.180 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 045 | Train loss: 0.6159 | Train score: 0.6581 | Val loss: 0.6231 | Val score: 0.6530
2024-02-20 20:35:16.038 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 046 | Train loss: 0.6104 | Train score: 0.6787 | Val loss: 0.6218 | Val score: 0.6570
2024-02-20 20:35:16.896 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 047 | Train loss: 0.6146 | Train score: 0.6731 | Val loss: 0.6212 | Val score: 0.6550
2024-02-20 20:35:17.755 | INFO     | tabularbench.core.trainer_finetune:train:86 - Epoch 048 | Train loss: 0.6009 | Train score: 0.6719 | Val loss: 0.6210 | Val score: 0.6565
2024-02-20 20:35:17.755 | INFO     | tabularbench.core.trainer_finetune:train:92 - Early stopping
2024-02-20 20:35:23.446 | INFO     | tabularbench.core.run_experiment:run_experiment:40 - Finished experiment on albert (id=45035) with Foundation doing CLASSIFICATION
2024-02-20 20:35:23.447 | INFO     | tabularbench.core.run_experiment:run_experiment:41 - Final scores: 
2024-02-20 20:35:23.448 | INFO     | tabularbench.core.run_experiment:run_experiment:44 - split_0 :: train: 0.6872, val: 0.6562, test: 0.6495
