2024-02-07 22:02:05.576 | INFO     | tabularbench.core.run_experiment:run_experiment:22 - Start experiment on albert (id=45035) with Foundation doing classification
2024-02-07 22:02:05.577 | INFO     | tabularbench.core.run_experiment:run_experiment:25 - Set seed to 0
2024-02-07 22:02:05.577 | INFO     | tabularbench.core.run_experiment:run_experiment:27 - We are using the following hyperparameters:
2024-02-07 22:02:05.577 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_features: 100
2024-02-07 22:02:05.577 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_classes: 10
2024-02-07 22:02:05.578 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     dim: 512
2024-02-07 22:02:05.578 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_layers: 12
2024-02-07 22:02:05.578 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_heads: 4
2024-02-07 22:02:05.578 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     attn_dropout: 0.0
2024-02-07 22:02:05.578 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     y_as_float_embedding: True
2024-02-07 22:02:05.578 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     linear_attention: True
2024-02-07 22:02:05.578 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     max_samples_support: 10000
2024-02-07 22:02:05.579 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     max_samples_query: 10000
2024-02-07 22:02:05.579 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     max_epochs: 300
2024-02-07 22:02:05.579 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     optimizer: adamw
2024-02-07 22:02:05.579 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     lr: 1e-05
2024-02-07 22:02:05.579 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     weight_decay: 0
2024-02-07 22:02:05.579 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     lr_scheduler: False
2024-02-07 22:02:05.579 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     lr_scheduler_patience: 30
2024-02-07 22:02:05.580 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     early_stopping_patience: 40
2024-02-07 22:02:05.580 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     use_pretrained_weights: True
2024-02-07 22:02:05.580 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     path_to_weights: outputs/2024-02-07/13-24-52/weights/model_step_60000.pt
2024-02-07 22:02:05.580 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_ensembles: 1
2024-02-07 22:02:05.580 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     use_quantile_transformer: True
2024-02-07 22:02:05.580 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     use_feature_count_scaling: True
2024-02-07 22:02:05.580 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     name: Foundation
2024-02-07 22:02:06.093 | INFO     | tabularbench.core.run_experiment:run_experiment_:61 - Start split 1/1 of albert (id=45035) with FOUNDATION doing CLASSIFICATION
2024-02-07 22:02:08.617 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 000 | Train loss: 0.6502 | Train score: 0.6413 | Val loss: 0.6298 | Val score: 0.6525
2024-02-07 22:02:10.099 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 001 | Train loss: 0.6317 | Train score: 0.6463 | Val loss: 0.6288 | Val score: 0.6550
2024-02-07 22:02:11.439 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 002 | Train loss: 0.6331 | Train score: 0.6544 | Val loss: 0.6264 | Val score: 0.6515
2024-02-07 22:02:12.784 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 003 | Train loss: 0.6297 | Train score: 0.6587 | Val loss: 0.6232 | Val score: 0.6530
2024-02-07 22:02:14.132 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 004 | Train loss: 0.6193 | Train score: 0.6606 | Val loss: 0.6213 | Val score: 0.6530
2024-02-07 22:02:15.601 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 005 | Train loss: 0.6232 | Train score: 0.6631 | Val loss: 0.6220 | Val score: 0.6560
2024-02-07 22:02:16.457 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 006 | Train loss: 0.6362 | Train score: 0.6344 | Val loss: 0.6215 | Val score: 0.6585
2024-02-07 22:02:17.313 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 007 | Train loss: 0.6204 | Train score: 0.6488 | Val loss: 0.6210 | Val score: 0.6530
2024-02-07 22:02:19.031 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 008 | Train loss: 0.6301 | Train score: 0.6587 | Val loss: 0.6206 | Val score: 0.6485
2024-02-07 22:02:20.860 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 009 | Train loss: 0.6259 | Train score: 0.6444 | Val loss: 0.6207 | Val score: 0.6505
2024-02-07 22:02:21.714 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 010 | Train loss: 0.6177 | Train score: 0.6569 | Val loss: 0.6211 | Val score: 0.6535
2024-02-07 22:02:22.569 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 011 | Train loss: 0.6265 | Train score: 0.6506 | Val loss: 0.6215 | Val score: 0.6550
2024-02-07 22:02:23.423 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 012 | Train loss: 0.6206 | Train score: 0.6544 | Val loss: 0.6217 | Val score: 0.6540
2024-02-07 22:02:24.280 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 013 | Train loss: 0.6347 | Train score: 0.6456 | Val loss: 0.6219 | Val score: 0.6565
2024-02-07 22:02:25.134 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 014 | Train loss: 0.6132 | Train score: 0.6625 | Val loss: 0.6216 | Val score: 0.6540
2024-02-07 22:02:25.989 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 015 | Train loss: 0.6320 | Train score: 0.6531 | Val loss: 0.6212 | Val score: 0.6555
2024-02-07 22:02:26.843 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 016 | Train loss: 0.6283 | Train score: 0.6519 | Val loss: 0.6210 | Val score: 0.6555
2024-02-07 22:02:27.705 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 017 | Train loss: 0.6205 | Train score: 0.6494 | Val loss: 0.6209 | Val score: 0.6520
2024-02-07 22:02:28.563 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 018 | Train loss: 0.6220 | Train score: 0.6625 | Val loss: 0.6212 | Val score: 0.6525
2024-02-07 22:02:29.420 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 019 | Train loss: 0.6371 | Train score: 0.6294 | Val loss: 0.6216 | Val score: 0.6525
2024-02-07 22:02:30.276 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 020 | Train loss: 0.6194 | Train score: 0.6594 | Val loss: 0.6219 | Val score: 0.6525
2024-02-07 22:02:31.132 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 021 | Train loss: 0.6256 | Train score: 0.6413 | Val loss: 0.6220 | Val score: 0.6550
2024-02-07 22:02:31.987 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 022 | Train loss: 0.6213 | Train score: 0.6531 | Val loss: 0.6218 | Val score: 0.6525
2024-02-07 22:02:32.842 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 023 | Train loss: 0.6228 | Train score: 0.6594 | Val loss: 0.6214 | Val score: 0.6570
2024-02-07 22:02:33.697 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 024 | Train loss: 0.6127 | Train score: 0.6606 | Val loss: 0.6212 | Val score: 0.6535
2024-02-07 22:02:34.552 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 025 | Train loss: 0.6204 | Train score: 0.6544 | Val loss: 0.6214 | Val score: 0.6535
2024-02-07 22:02:35.406 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 026 | Train loss: 0.6286 | Train score: 0.6525 | Val loss: 0.6217 | Val score: 0.6565
2024-02-07 22:02:36.261 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 027 | Train loss: 0.6122 | Train score: 0.6594 | Val loss: 0.6220 | Val score: 0.6545
2024-02-07 22:02:37.116 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 028 | Train loss: 0.6238 | Train score: 0.6581 | Val loss: 0.6226 | Val score: 0.6520
2024-02-07 22:02:37.971 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 029 | Train loss: 0.6152 | Train score: 0.6531 | Val loss: 0.6234 | Val score: 0.6530
2024-02-07 22:02:38.824 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 030 | Train loss: 0.6110 | Train score: 0.6481 | Val loss: 0.6246 | Val score: 0.6515
2024-02-07 22:02:39.679 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 031 | Train loss: 0.6267 | Train score: 0.6419 | Val loss: 0.6255 | Val score: 0.6495
2024-02-07 22:02:40.535 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 032 | Train loss: 0.6317 | Train score: 0.6362 | Val loss: 0.6259 | Val score: 0.6545
2024-02-07 22:02:41.390 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 033 | Train loss: 0.6069 | Train score: 0.6725 | Val loss: 0.6255 | Val score: 0.6540
2024-02-07 22:02:42.246 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 034 | Train loss: 0.6249 | Train score: 0.6456 | Val loss: 0.6249 | Val score: 0.6530
2024-02-07 22:02:43.102 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 035 | Train loss: 0.6116 | Train score: 0.6669 | Val loss: 0.6239 | Val score: 0.6535
2024-02-07 22:02:43.957 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 036 | Train loss: 0.6030 | Train score: 0.6706 | Val loss: 0.6229 | Val score: 0.6525
2024-02-07 22:02:44.813 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 037 | Train loss: 0.6133 | Train score: 0.6637 | Val loss: 0.6224 | Val score: 0.6595
2024-02-07 22:02:45.669 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 038 | Train loss: 0.6030 | Train score: 0.6794 | Val loss: 0.6226 | Val score: 0.6580
2024-02-07 22:02:46.525 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 039 | Train loss: 0.6303 | Train score: 0.6463 | Val loss: 0.6235 | Val score: 0.6550
2024-02-07 22:02:47.392 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 040 | Train loss: 0.6106 | Train score: 0.6631 | Val loss: 0.6240 | Val score: 0.6555
2024-02-07 22:02:48.247 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 041 | Train loss: 0.6085 | Train score: 0.6744 | Val loss: 0.6244 | Val score: 0.6615
2024-02-07 22:02:49.104 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 042 | Train loss: 0.6048 | Train score: 0.6719 | Val loss: 0.6249 | Val score: 0.6555
2024-02-07 22:02:49.963 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 043 | Train loss: 0.6294 | Train score: 0.6681 | Val loss: 0.6255 | Val score: 0.6540
2024-02-07 22:02:50.828 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 044 | Train loss: 0.6017 | Train score: 0.6737 | Val loss: 0.6266 | Val score: 0.6535
2024-02-07 22:02:51.689 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 045 | Train loss: 0.6120 | Train score: 0.6694 | Val loss: 0.6275 | Val score: 0.6510
2024-02-07 22:02:52.549 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 046 | Train loss: 0.6073 | Train score: 0.6806 | Val loss: 0.6282 | Val score: 0.6495
2024-02-07 22:02:53.406 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 047 | Train loss: 0.6084 | Train score: 0.6719 | Val loss: 0.6291 | Val score: 0.6425
2024-02-07 22:02:54.263 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 048 | Train loss: 0.5973 | Train score: 0.6756 | Val loss: 0.6293 | Val score: 0.6405
2024-02-07 22:02:54.264 | INFO     | tabularbench.core.trainer_finetune:train:91 - Early stopping
2024-02-07 22:03:00.006 | INFO     | tabularbench.core.run_experiment:run_experiment:40 - Finished experiment on albert (id=45035) with Foundation doing CLASSIFICATION
2024-02-07 22:03:00.007 | INFO     | tabularbench.core.run_experiment:run_experiment:41 - Final scores: 
2024-02-07 22:03:00.007 | INFO     | tabularbench.core.run_experiment:run_experiment:44 - split_0 :: train: 0.7034, val: 0.6522, test: 0.6451
