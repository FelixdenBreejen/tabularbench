2024-02-09 09:08:58.833 | INFO     | tabularbench.core.run_experiment:run_experiment:22 - Start experiment on albert (id=45035) with Foundation doing classification
2024-02-09 09:08:58.834 | INFO     | tabularbench.core.run_experiment:run_experiment:25 - Set seed to 6
2024-02-09 09:08:58.834 | INFO     | tabularbench.core.run_experiment:run_experiment:27 - We are using the following hyperparameters:
2024-02-09 09:08:58.834 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_features: 100
2024-02-09 09:08:58.835 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_classes: 10
2024-02-09 09:08:58.835 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     dim: 512
2024-02-09 09:08:58.835 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_layers: 12
2024-02-09 09:08:58.835 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_heads: 4
2024-02-09 09:08:58.835 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     attn_dropout: 0.0
2024-02-09 09:08:58.835 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     y_as_float_embedding: True
2024-02-09 09:08:58.835 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     linear_attention: True
2024-02-09 09:08:58.836 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     max_samples_support: 10000
2024-02-09 09:08:58.836 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     max_samples_query: 10000
2024-02-09 09:08:58.836 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     max_epochs: 300
2024-02-09 09:08:58.836 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     optimizer: adamw
2024-02-09 09:08:58.836 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     lr: 1e-05
2024-02-09 09:08:58.836 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     weight_decay: 0
2024-02-09 09:08:58.836 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     lr_scheduler: False
2024-02-09 09:08:58.836 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     lr_scheduler_patience: 30
2024-02-09 09:08:58.837 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     early_stopping_patience: 40
2024-02-09 09:08:58.837 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     use_pretrained_weights: True
2024-02-09 09:08:58.837 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     path_to_weights: outputs/2024-02-07/13-24-52/weights/model_step_300000.pt
2024-02-09 09:08:58.837 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     n_ensembles: 1
2024-02-09 09:08:58.837 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     use_quantile_transformer: True
2024-02-09 09:08:58.837 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     use_feature_count_scaling: True
2024-02-09 09:08:58.837 | INFO     | tabularbench.core.run_experiment:run_experiment:29 -     name: Foundation
2024-02-09 09:08:59.383 | INFO     | tabularbench.core.run_experiment:run_experiment_:61 - Start split 1/1 of albert (id=45035) with FOUNDATION doing CLASSIFICATION
2024-02-09 09:09:01.990 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 000 | Train loss: 0.6462 | Train score: 0.6400 | Val loss: 0.6519 | Val score: 0.6295
2024-02-09 09:09:03.548 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 001 | Train loss: 0.6401 | Train score: 0.6375 | Val loss: 0.6411 | Val score: 0.6390
2024-02-09 09:09:05.237 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 002 | Train loss: 0.6456 | Train score: 0.6162 | Val loss: 0.6374 | Val score: 0.6400
2024-02-09 09:09:06.921 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 003 | Train loss: 0.6142 | Train score: 0.6644 | Val loss: 0.6352 | Val score: 0.6410
2024-02-09 09:09:08.626 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 004 | Train loss: 0.6285 | Train score: 0.6562 | Val loss: 0.6338 | Val score: 0.6460
2024-02-09 09:09:10.296 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 005 | Train loss: 0.6239 | Train score: 0.6587 | Val loss: 0.6330 | Val score: 0.6510
2024-02-09 09:09:11.967 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 006 | Train loss: 0.6284 | Train score: 0.6444 | Val loss: 0.6327 | Val score: 0.6555
2024-02-09 09:09:13.691 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 007 | Train loss: 0.6234 | Train score: 0.6425 | Val loss: 0.6324 | Val score: 0.6575
2024-02-09 09:09:15.486 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 008 | Train loss: 0.6207 | Train score: 0.6513 | Val loss: 0.6322 | Val score: 0.6555
2024-02-09 09:09:17.236 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 009 | Train loss: 0.6131 | Train score: 0.6625 | Val loss: 0.6324 | Val score: 0.6555
2024-02-09 09:09:18.125 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 010 | Train loss: 0.6130 | Train score: 0.6581 | Val loss: 0.6330 | Val score: 0.6580
2024-02-09 09:09:18.990 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 011 | Train loss: 0.6089 | Train score: 0.6687 | Val loss: 0.6341 | Val score: 0.6500
2024-02-09 09:09:19.854 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 012 | Train loss: 0.6185 | Train score: 0.6662 | Val loss: 0.6352 | Val score: 0.6505
2024-02-09 09:09:20.717 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 013 | Train loss: 0.6157 | Train score: 0.6569 | Val loss: 0.6356 | Val score: 0.6540
2024-02-09 09:09:21.580 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 014 | Train loss: 0.6150 | Train score: 0.6425 | Val loss: 0.6350 | Val score: 0.6540
2024-02-09 09:09:22.444 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 015 | Train loss: 0.6059 | Train score: 0.6562 | Val loss: 0.6345 | Val score: 0.6510
2024-02-09 09:09:23.307 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 016 | Train loss: 0.6054 | Train score: 0.6687 | Val loss: 0.6343 | Val score: 0.6530
2024-02-09 09:09:24.170 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 017 | Train loss: 0.6029 | Train score: 0.6694 | Val loss: 0.6346 | Val score: 0.6510
2024-02-09 09:09:25.031 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 018 | Train loss: 0.6227 | Train score: 0.6438 | Val loss: 0.6339 | Val score: 0.6470
2024-02-09 09:09:25.894 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 019 | Train loss: 0.6208 | Train score: 0.6569 | Val loss: 0.6335 | Val score: 0.6510
2024-02-09 09:09:26.756 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 020 | Train loss: 0.6065 | Train score: 0.6662 | Val loss: 0.6333 | Val score: 0.6490
2024-02-09 09:09:27.619 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 021 | Train loss: 0.6068 | Train score: 0.6700 | Val loss: 0.6332 | Val score: 0.6465
2024-02-09 09:09:28.481 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 022 | Train loss: 0.6164 | Train score: 0.6556 | Val loss: 0.6332 | Val score: 0.6500
2024-02-09 09:09:29.343 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 023 | Train loss: 0.6140 | Train score: 0.6656 | Val loss: 0.6330 | Val score: 0.6495
2024-02-09 09:09:30.205 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 024 | Train loss: 0.5971 | Train score: 0.6806 | Val loss: 0.6336 | Val score: 0.6520
2024-02-09 09:09:31.066 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 025 | Train loss: 0.5990 | Train score: 0.6731 | Val loss: 0.6349 | Val score: 0.6505
2024-02-09 09:09:31.927 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 026 | Train loss: 0.6011 | Train score: 0.6662 | Val loss: 0.6366 | Val score: 0.6475
2024-02-09 09:09:32.790 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 027 | Train loss: 0.6149 | Train score: 0.6575 | Val loss: 0.6377 | Val score: 0.6490
2024-02-09 09:09:33.652 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 028 | Train loss: 0.6244 | Train score: 0.6575 | Val loss: 0.6380 | Val score: 0.6515
2024-02-09 09:09:34.513 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 029 | Train loss: 0.6010 | Train score: 0.6731 | Val loss: 0.6385 | Val score: 0.6470
2024-02-09 09:09:35.373 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 030 | Train loss: 0.6009 | Train score: 0.6675 | Val loss: 0.6390 | Val score: 0.6495
2024-02-09 09:09:36.236 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 031 | Train loss: 0.6177 | Train score: 0.6544 | Val loss: 0.6390 | Val score: 0.6510
2024-02-09 09:09:37.099 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 032 | Train loss: 0.6220 | Train score: 0.6644 | Val loss: 0.6385 | Val score: 0.6505
2024-02-09 09:09:37.963 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 033 | Train loss: 0.5977 | Train score: 0.6731 | Val loss: 0.6385 | Val score: 0.6460
2024-02-09 09:09:38.826 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 034 | Train loss: 0.6252 | Train score: 0.6562 | Val loss: 0.6383 | Val score: 0.6460
2024-02-09 09:09:39.688 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 035 | Train loss: 0.5946 | Train score: 0.6806 | Val loss: 0.6385 | Val score: 0.6460
2024-02-09 09:09:40.550 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 036 | Train loss: 0.5980 | Train score: 0.6706 | Val loss: 0.6390 | Val score: 0.6440
2024-02-09 09:09:41.413 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 037 | Train loss: 0.5866 | Train score: 0.6844 | Val loss: 0.6402 | Val score: 0.6425
2024-02-09 09:09:42.275 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 038 | Train loss: 0.6022 | Train score: 0.6681 | Val loss: 0.6414 | Val score: 0.6435
2024-02-09 09:09:43.136 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 039 | Train loss: 0.6055 | Train score: 0.6712 | Val loss: 0.6422 | Val score: 0.6475
2024-02-09 09:09:44.006 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 040 | Train loss: 0.6093 | Train score: 0.6650 | Val loss: 0.6428 | Val score: 0.6465
2024-02-09 09:09:44.880 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 041 | Train loss: 0.6075 | Train score: 0.6587 | Val loss: 0.6431 | Val score: 0.6455
2024-02-09 09:09:45.758 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 042 | Train loss: 0.5930 | Train score: 0.6837 | Val loss: 0.6435 | Val score: 0.6455
2024-02-09 09:09:46.623 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 043 | Train loss: 0.5975 | Train score: 0.6719 | Val loss: 0.6439 | Val score: 0.6425
2024-02-09 09:09:47.494 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 044 | Train loss: 0.6013 | Train score: 0.6656 | Val loss: 0.6441 | Val score: 0.6425
2024-02-09 09:09:48.357 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 045 | Train loss: 0.6042 | Train score: 0.6719 | Val loss: 0.6437 | Val score: 0.6380
2024-02-09 09:09:49.221 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 046 | Train loss: 0.6019 | Train score: 0.6787 | Val loss: 0.6434 | Val score: 0.6355
2024-02-09 09:09:50.085 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 047 | Train loss: 0.5970 | Train score: 0.6806 | Val loss: 0.6433 | Val score: 0.6385
2024-02-09 09:09:50.948 | INFO     | tabularbench.core.trainer_finetune:train:85 - Epoch 048 | Train loss: 0.5927 | Train score: 0.6894 | Val loss: 0.6438 | Val score: 0.6400
2024-02-09 09:09:50.948 | INFO     | tabularbench.core.trainer_finetune:train:91 - Early stopping
2024-02-09 09:09:56.692 | INFO     | tabularbench.core.run_experiment:run_experiment:40 - Finished experiment on albert (id=45035) with Foundation doing CLASSIFICATION
2024-02-09 09:09:56.693 | INFO     | tabularbench.core.run_experiment:run_experiment:41 - Final scores: 
2024-02-09 09:09:56.693 | INFO     | tabularbench.core.run_experiment:run_experiment:44 - split_0 :: train: 0.6937, val: 0.6482, test: 0.6509
